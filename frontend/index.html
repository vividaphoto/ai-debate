<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="utf-8" />
  <title>AI Debate - Edge Proxy Streaming</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    :root {
      --bg:#0f172a; --panel:#111827; --muted:#9ca3af; --text:#e5e7eb;
      --border:#1f2937; --accent:#22d3ee; --ok:#22c55e; --warn:#f59e0b;
    }
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:var(--text);font-family:ui-sans-serif,system-ui,Segoe UI,Roboto,Arial}
    header{padding:16px 20px;border-bottom:1px solid var(--border);display:flex;align-items:center;gap:10px}
    h1{margin:0;font-size:18px}
    .badge{font-size:12px;border:1px solid var(--border);padding:4px 8px;border-radius:999px;color:#a5f3fc}
    main{max-width:1100px;margin:0 auto;padding:16px}
    .card{background:var(--panel);border:1px solid var(--border);border-radius:12px;padding:12px}
    .grid{display:grid;grid-template-columns:1fr;gap:12px}
    @media(min-width:980px){.grid{grid-template-columns:300px 1fr}}
    label{display:block;font-size:12px;color:var(--muted);margin-bottom:6px}
    input,textarea{width:100%;background:#0b1220;color:var(--text);border:1px solid var(--border);border-radius:10px;padding:10px}
    textarea{min-height:110px;resize:vertical}
    .row{display:grid;grid-template-columns:1fr 1fr;gap:8px}
    .btn{cursor:pointer;border:1px solid var(--border);background:linear-gradient(180deg,#0ea5b7,#0b5561);color:#e6fffb;padding:10px 14px;border-radius:12px;font-weight:600}
    .btn.secondary{background:#0b1220;color:var(--text)}
    .columns{display:grid;grid-template-columns:1fr;gap:12px}
    @media(min-width:980px){.columns{grid-template-columns:1fr 1fr}}
    .col{background:#0b1220;border:1px dashed #243042;border-radius:12px;padding:12px;min-height:160px}
    .title{display:flex;align-items:center;justify-content:space-between}
    .pill{font-size:11px;padding:3px 8px;border-radius:999px;border:1px solid #243042;color:#93c5fd}
    pre{white-space:pre-wrap;word-wrap:break-word}
    .log{background:#0b1220;border:1px solid var(--border);border-radius:12px;padding:10px;max-height:240px;overflow:auto;font-size:12px}
    .muted{color:var(--muted);font-size:12px}
  </style>
</head>
<body>
<header>
  <h1>AI Debate - Edge Proxy</h1>
  <span class="badge">Streaming + Convergenza</span>
</header>

<main>
  <div class="grid">
    <section class="card">
      <strong>Impostazioni</strong>
      <div style="height:8px"></div>
      <label>Worker Base URL</label>
      <input id="workerBase" placeholder="https://ai-debate-proxy.TUO-SUB.workers.dev" />
      <div class="row" style="margin-top:8px">
        <div>
          <label>Modello OpenAI</label>
          <input id="openaiModel" value="gpt-4o" />
        </div>
        <div>
          <label>Modello Anthropic</label>
          <input id="anthropicModel" value="claude-3-5-sonnet-latest" />
        </div>
      </div>
      <div class="row" style="margin-top:8px">
        <div>
          <label>Temperature</label>
          <input id="temperature" value="0.3" />
        </div>
        <div>
          <label>Max tokens</label>
          <input id="maxTokens" value="800" />
        </div>
      </div>
      <div class="row" style="margin-top:8px">
        <div>
          <label>Max turni</label>
          <input id="maxTurns" value="3" />
        </div>
        <div>
          <label>Soglia convergenza (0-1)</label>
          <input id="threshold" value="0.6" />
        </div>
      </div>
    </section>

    <section class="card">
      <label>Domanda iniziale</label>
      <textarea id="question" placeholder="Scrivi la domanda..."></textarea>
      <div class="row" style="margin-top:8px">
        <button class="btn" id="startBtn">Avvia debate</button>
        <button class="btn secondary" id="stopBtn">Stop</button>
      </div>
      <p class="muted" style="margin-top:8px">
        Le chiavi API sono custodite nel Worker (edge). Il browser non vede mai i segreti.
      </p>
    </section>
  </div>

  <section class="columns" style="margin-top:12px">
    <div class="col">
      <div class="title"><strong>Modello A (OpenAI)</strong><span id="badgeA" class="pill">gpt-4o</span></div>
      <pre id="outA">-</pre>
    </div>
    <div class="col">
      <div class="title"><strong>Modello B (Claude)</strong><span id="badgeB" class="pill">claude-3-5-sonnet-latest</span></div>
      <pre id="outB">-</pre>
    </div>
  </section>

  <section class="card" style="margin-top:12px">
    <strong>Log</strong>
    <div id="log" class="log"></div>
  </section>
</main>

<script>
const $ = (id)=>document.getElementById(id);
const log = (m)=>{ const d=document.createElement("div"); d.textContent=m; $("log").appendChild(d); $("log").scrollTop=$("log").scrollHeight; };

function ngrams(t,n){ const tok=(t||"").toLowerCase().replace(/\s+/g," ").split(" "); const out=[]; for(let i=0;i<=tok.length-n;i++) out.push(tok.slice(i,i+n).join(" ")); return out; }
function jaccard(a,b){ const A=new Set(ngrams(a,3)), B=new Set(ngrams(b,3)); const inter=[...A].filter(x=>B.has(x)).length; const uni=new Set([...A,...B]).size; return uni?inter/uni:0; }

let aborted=false;
$("stopBtn").addEventListener("click", ()=>{ aborted=true; log("Interrotto dall'utente"); });

$("startBtn").addEventListener("click", async ()=>{
  aborted=false;
  const WORKER_BASE = $("workerBase").value.trim();
  const A_MODEL = $("openaiModel").value.trim() || "gpt-4o";
  const B_MODEL = $("anthropicModel").value.trim() || "claude-3-5-sonnet-latest";
  $("badgeA").textContent = A_MODEL;
  $("badgeB").textContent = B_MODEL;

  const temperature = parseFloat($("temperature").value || "0.3");
  const max_tokens = parseInt($("maxTokens").value || "800", 10);
  const maxTurns = Math.max(1, parseInt($("maxTurns").value || "3", 10));
  const threshold = Math.min(1, Math.max(0, parseFloat($("threshold").value || "0.6")));
  const question = $("question").value.trim();

  if (!WORKER_BASE || !question) { log("Inserisci Worker URL e una domanda."); return; }

  $("outA").textContent = ""; $("outB").textContent = ""; $("log").textContent = "";
  log("Avvio dibattito via Edge Proxy...");

  try {
    let A = await callOpenAI_stream(WORKER_BASE, A_MODEL, [{role:"user", content:question}], temperature, max_tokens, (d)=>{ $("outA").textContent += d; });
    log("Turno 1 - A risponde");
    if (aborted) return;

    let B = await callAnthropic_stream(WORKER_BASE, B_MODEL, question, temperature, max_tokens, (d)=>{ $("outB").textContent += d; });
    log("Turno 1 - B risponde");
    if (aborted) return;

    let t=1;
    while (t < maxTurns && !aborted) {
      const s1 = jaccard(A, B);
      log(`Similarita(A,B) = ${s1.toFixed(3)}`);
      if (s1 >= threshold) { log("Convergenza raggiunta"); break; }

      // B critica A
      const critiquePrompt = `Valuta criticamente e poi migliora questa risposta. Prima bullet points di valutazione, poi versione rivista:\n\n${A}`;
      $("outB").textContent = ""; // pulizia per lo stream nuovo
      B = await callAnthropic_stream(WORKER_BASE, B_MODEL, critiquePrompt, temperature, max_tokens, (d)=>{ $("outB").textContent += d; });
      log(`Turno ${t+1} - B rifinisce A`);
      if (aborted) break;

      const s2 = jaccard(A,B);
      log(`Similarita(A,B) = ${s2.toFixed(3)}`);
      if (s2 >= threshold) { log("Convergenza raggiunta"); break; }

      // A integra feedback di B
      const revisePrompt = `Integra i punti utili del seguente feedback e restituisci una risposta piu chiara e azionabile:\n\n${B}`;
      $("outA").textContent = "";
      A = await callOpenAI_stream(WORKER_BASE, A_MODEL, [{role:"user", content:revisePrompt}], temperature, max_tokens, (d)=>{ $("outA").textContent += d; });
      log(`Turno ${t+1} - A integra B`);

      t++;
    }

    if (aborted) log("Dibattito interrotto.");
    else log("Dibattito concluso.");

  } catch (e) {
    console.error(e);
    log("Errore: " + (e?.message || e));
  }
});

async function callOpenAI_stream(base, model, messages, temperature, max_tokens, onDelta){
  const res = await fetch(`${base}/openai`, {
    method: "POST",
    headers: {"Content-Type":"application/json"},
    body: JSON.stringify({ model, messages, temperature, max_tokens, stream:true })
  });
  if (!res.ok || !res.body) throw new Error("OpenAI proxy error " + res.status);
  const reader = res.body.getReader();
  const dec = new TextDecoder();
  let full = "";
  while (true) {
    const {value, done} = await reader.read();
    if (done) break;
    const chunk = dec.decode(value);
    for (const line of chunk.split("\n")) {
      if (!line.startsWith("data:")) continue;
      const data = line.slice(5).trim();
      if (!data || data === "[DONE]") continue;
      try {
        const json = JSON.parse(data);
        const delta = json.choices?.[0]?.delta?.content || "";
        if (delta) { full += delta; onDelta?.(delta); }
      } catch {}
    }
  }
  return full;
}

async function callAnthropic_stream(base, model, userText, temperature, max_tokens, onDelta){
  const res = await fetch(`${base}/anthropic`, {
    method: "POST",
    headers: {"Content-Type":"application/json"},
    body: JSON.stringify({
      model, temperature, max_tokens, stream:true,
      messages: [{ role:"user", content: userText }]
    })
  });
  if (!res.ok || !res.body) throw new Error("Anthropic proxy error " + res.status);
  const reader = res.body.getReader();
  const dec = new TextDecoder();
  let full = "";
  while (true) {
    const {value, done} = await reader.read();
    if (done) break;
    const chunk = dec.decode(value);
    for (const line of chunk.split("\n")) {
      if (!line.startsWith("data:")) continue;
      const data = line.slice(5).trim();
      if (!data || data === "[DONE]") continue;
      try {
        const evt = JSON.parse(data);
        const delta = evt.delta?.text || evt.content_block?.text || "";
        if (delta) { full += delta; onDelta?.(delta); }
      } catch {}
    }
  }
  return full;
}
</script>
</body>
</html>